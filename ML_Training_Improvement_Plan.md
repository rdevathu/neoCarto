# üìà Improving AF/AT Recurrence Prediction on Small, Imbalanced ECG Data

## 1. Quick Diagnosis of Why ROC‚âà0.50

| Hypothesis | Evidence to Gather | How to Check |
|------------|-------------------|--------------|
| 1. **Severe class imbalance not handled** | ROCKET/ResNet pipeline *silently* skips `RandomOverSampler` because data are 3-D | Inspect log: `logger.warning("Oversampling not supported with rocket ..." )` ‚Üí confirm minority ratio in `results["class_distribution"]` |
| 2. **Label / cohort mismatch** (e.g. pre-ECG window too far from recurrence event) | High label noise will keep AUC at chance | Plot label distribution vs. time-to-event; sanity-check a few records |
| 3. **Data leakage + small folds** cause overfit (train AUC‚â´val/holdout) | CV summary already logged‚Äîcompare `train_metrics` to `val_metrics` | If train AUC‚â´0.9 but val‚âà0.5 ‚Üí leakage/overfit |
| 4. **Model choice not suited** (ROCKET logistic is linear; signal may be subtle) | Try very small baseline (heartbeat averages) to see if any signal exists | If even deep networks fail, signal might truly be weak |

## 2. Guiding Principles for Improvements

1. **Keep pipeline simple & reproducible** ‚Äì prefer scikit-learn primitives over bespoke deep nets.
2. **Exploit every label** but **never leak patients** across splits.
3. **Treat imbalance explicitly** via *sample weights* or *post-ROCKET oversampling* rather than hacking 3-D resampling.
4. **Measure properly** ‚Äì use PR-AUC in addition to ROC-AUC; always compare to both *majority* and *random* baselines.

## 3. Minimal, High-Impact Changes

### 3.1 Swap `RocketClassifier` for `RocketTransformer ‚Üí LogisticRegression`

```python
from sktime.transformations.panel.rocket import Rocket
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from imblearn.over_sampling import RandomOverSampler

rocket = Rocket(num_kernels=10_000, random_state=42)
os = RandomOverSampler(random_state=42)
logreg = LogisticRegression(max_iter=1000, class_weight="balanced", C=1.0)
pipe = make_pipeline(rocket, os, logreg)
```

Why?
* `RocketClassifier` wraps a **fixed** logistic reg **without** class_weight. Breaking it apart lets us a) oversample **after** flattening to 2-D, b) tune `C`, and c) inject `class_weight="balanced"`.

### 3.2 Instance-level Sample Weighting (no oversampling needed)

If oversampling blows up memory, simply pass `sample_weight` when calling `fit()` on classifiers that support it.

### 3.3 Stratified, Grouped CV with Larger Folds

Use `StratifiedGroupKFold` (scikit-learn ‚â•1.2) to keep patient groups intact **and** balance labels across folds.

### 3.4 Hyper-Parameter Search (but lightweight)

Grid to explore and keep runtimes reasonable:

| Parameter | Values |
|-----------|--------|
| `num_kernels` | 2k, 10k (default 10k), 20k |
| `C` (logistic) | 0.1, 1, 10 |
| `class_weight` | `balanced`, custom {0:1,1:3} |

Use `RandomizedSearchCV(n_iter=8)` to finish in minutes.

### 3.5 Data-Level Tactics

1. **Patient Bootstrapping:** duplicate minority-class patients at the *patient* level so all their ECGs stay together ‚ûú avoid leakage.
2. **Noise Filtering:** drop recordings with missing leads / extreme artifacts before training.
3. **Time-Window Selection:** start with the closest window (`pre_ecg_1y`) where the signal is likely strongest; only add longer windows after success.

## 4. Concrete Step-by-Step Plan for the LLM

### ‚úÖ **COMPLETED STEPS:**
1. **Add utilities** ‚úÖ
   1. ‚úÖ Implement `scripts/analyse_class_balance.py` to print positive-ratio per window/outcome.
   2. ‚úÖ Add `utils/cv_helpers.py` with `StratifiedGroupKFold` wrapper.
2. **Refactor `train.py`** ‚úÖ
   1. ‚úÖ Replace `get_model()` rocket branch with transformer + logistic approach above.
   2. ‚úÖ Insert optional `--class-weight balanced` flag.
   3. ‚úÖ Allow `--sample-weight` to toggle passing weights instead of oversampling.

### üö® **URGENT FIXES NEEDED:**
3. **Fix Overfitting Issues** üîÑ
   1. **Increase regularization**: Default C=0.1 instead of C=1.0
   2. **Reduce ROCKET kernels**: Use 2000-5000 instead of 10000 for small dataset
   3. **Add early stopping**: Monitor validation performance
   4. **Cross-validation improvements**: Use stratified group k-fold with k=3 (larger folds)
4. **Improve Data Strategy** üîÑ
   1. **Focus on all leads only**: Single lead shows no signal
   2. **Patient-level bootstrapping**: Duplicate minority patients to increase effective sample size
   3. **Feature selection**: Add L1 regularization option

### ‚è≥ **REMAINING STEPS:**
5. **Implement Hyper-Parameter Search** (only when `--tune` flag passed):
   * Use `RandomizedSearchCV` on the pipeline; scoring = `average_precision`.
6. **Update `run_experiments.py`**
   * ‚úÖ Add flags: `--tune`, `--class-weight`.
   * üîÑ Reduce config grid size; focus on best window/outcome first.
7. **Validation Checks**
   * Write `notebooks/01_error_analysis.ipynb` to plot ROC & PR curves per fold and confusion matrices.
   * If ROC still ‚âà0.5, revisit label/censoring logic in `preprocess.py`.
8. **Documentation**
   * Create `docs/training_guidelines.md` summarizing best practices & the results of balance analysis.

## 5. Milestones & Expected Gains

| Milestone | Metric Target | Status |
|-----------|---------------|--------|
| After class weighting | ROC-AUC ‚â•0.60 | ‚ùå **0.595 achieved, but severe overfitting** |
| After regularization fixes | ROC-AUC ‚â•0.60 stable | üîÑ **Next priority** |
| After hyper-parameter search | ROC-AUC ‚â•0.65, PR-AUC ‚Üë | ‚è≥ Pending |
| After data cleaning & window tuning | ROC-AUC ‚â•0.70 | ‚è≥ Pending |

**‚ö†Ô∏è CRITICAL ISSUES FOUND:**
- **Severe overfitting**: Train AUC=1.0, Val AUC=0.47
- **Single lead failure**: Lead1 shows random performance (AUC‚âà0.50)
- **Small fold instability**: High variance across CV folds

## 6. Future Ideas (if still plateauing)

* **Ensemble Averaging across Windows** ‚Äì majority vote over multiple ECGs per patient.
* **Self-Supervised Pre-training** on all sinus rhythm ECGs ‚ûú finetune on recurrence labels (requires extra code, so postpone).
* **Feature Attribution Checks** with `SHAP` to verify the model sees physiologically plausible patterns.

---
*Prepared 2025-07-06 ‚Äî v1.* 